{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#from data_handler_gesture import DataHandler\n",
    "from data_handler_gesture_2 import DataHandler\n",
    "from models import create_grud_model, load_grud_model\n",
    "from nn_utils.callbacks import ModelCheckpointwithBestWeights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GPU usage for tensorflow backend\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = .1\n",
    "    config.gpu_options.allow_growth = True\n",
    "    K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: Namespace(batch_size=32, dataset_name='gesture', early_stopping_patience=10, epochs=100, hidden_dim=[], label_name='phase', max_timestamp=5807537, max_timesteps=200, model='GRUD', pretrained_model_file=None, recurrent_dim=[64], use_bidirectional_rnn=False, working_path='.')\n"
     ]
    }
   ],
   "source": [
    "# parse arguments\n",
    "## general\n",
    "arg_parser = argparse.ArgumentParser()\n",
    "arg_parser.add_argument('--working_path', default='.')\n",
    "\n",
    "## data\n",
    "arg_parser.add_argument('dataset_name', default='mimic3',\n",
    "                        help='The data files should be saved in [working_path]/data/[dataset_name] directory.')\n",
    "arg_parser.add_argument('label_name', default='mortality')\n",
    "arg_parser.add_argument('--max_timesteps', type=int, default=200, \n",
    "                        help='Time series of at most # time steps are used. Default: 200.')\n",
    "arg_parser.add_argument('--max_timestamp', type=int, default=48*60*60,\n",
    "                        help='Time series of at most # seconds are used. Default: 48 (hours).')\n",
    "\n",
    "## model\n",
    "arg_parser.add_argument('--recurrent_dim', type=lambda x: x and [int(xx) for xx in x.split(',')] or [], default='64')\n",
    "arg_parser.add_argument('--hidden_dim', type=lambda x: x and [int(xx) for xx in x.split(',')] or [], default='64')\n",
    "arg_parser.add_argument('--model', default='GRUD', choices=['GRUD', 'GRUforward', 'GRU0', 'GRUsimple'])\n",
    "arg_parser.add_argument('--use_bidirectional_rnn', default=False)\n",
    "                           \n",
    "## training\n",
    "arg_parser.add_argument('--pretrained_model_file', default=None,\n",
    "                        help='If pre-trained model is provided, training will be skipped.') # e.g., [model_name]_[i_fold].h5\n",
    "arg_parser.add_argument('--epochs', type=int, default=100)\n",
    "arg_parser.add_argument('--early_stopping_patience', type=int, default=10)\n",
    "arg_parser.add_argument('--batch_size', type=int, default=32)\n",
    "\n",
    "\n",
    "## set the actual arguments if running in notebook\n",
    "if not (__name__ == '__main__' and '__file__' in globals()):\n",
    "    '''ARGS = arg_parser.parse_args([\n",
    "        'mimic3',\n",
    "        'mortality',\n",
    "        '--model', 'GRUD',\n",
    "        '--hidden_dim', '',\n",
    "        '--epochs', '100'\n",
    "    ])'''\n",
    "    ARGS = arg_parser.parse_args([\n",
    "        'gesture',\n",
    "        'phase',\n",
    "        '--model', 'GRUD',\n",
    "        '--hidden_dim', '',\n",
    "        '--max_timestamp', '5807537',\n",
    "        '--epochs', '100'\n",
    "    ])\n",
    "else:\n",
    "    ARGS = arg_parser.parse_args()\n",
    "\n",
    "print('Arguments:', ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase\n"
     ]
    }
   ],
   "source": [
    "print(ARGS.label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gesture\n"
     ]
    }
   ],
   "source": [
    "print(ARGS.dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "\n",
    "dataset = DataHandler(\n",
    "    data_path=os.path.join(ARGS.working_path, 'data', ARGS.dataset_name), \n",
    "    label_name=ARGS.label_name, \n",
    "    max_steps=ARGS.max_timesteps,\n",
    "    max_timestamp=ARGS.max_timestamp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 20191220_151839_702297\n",
      "0-th fold...\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3080: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 18)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 18)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "external_masking_1 (ExternalMas (None, None, 18)     0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 18)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "external_masking_2 (ExternalMas (None, None, 1)      0           input_3[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "grud_1 (GRUD)                   (None, 64)           20644       external_masking_1[0][0]         \n",
      "                                                                 masking_1[0][0]                  \n",
      "                                                                 external_masking_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           grud_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            65          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,709\n",
      "Trainable params: 20,709\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-14b3b6ad55c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 ),\n\u001b[0;32m     39\u001b[0m                 TensorBoard(\n\u001b[1;32m---> 40\u001b[1;33m                     \u001b[0mlog_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mARGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworking_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tb_logs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m                 )\n\u001b[0;32m     42\u001b[0m             ]\n",
      "\u001b[1;32mD:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     \u001b[1;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[1;32m--> 709\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    694\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Nouveau dossier\\envs\\pfe-ia\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[1;34m(uid)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \"\"\"\n\u001b[1;32m--> 626\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PFE-IA\\data_handler.py\u001b[0m in \u001b[0;36m_generator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    127\u001b[0m                     \u001b[0mbatch_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_from\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_from\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                     inputs = [self._data[s][batch_fold] for s\n\u001b[1;32m--> 129\u001b[1;33m                               in ['input', 'masking', 'timestamp']]\n\u001b[0m\u001b[0;32m    130\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rescale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[0mlens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PFE-IA\\data_handler.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0mbatch_from\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                     \u001b[0mbatch_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_from\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_from\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                     inputs = [self._data[s][batch_fold] for s\n\u001b[0m\u001b[0;32m    129\u001b[0m                               in ['input', 'masking', 'timestamp']]\n\u001b[0;32m    130\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rescale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "# k-fold cross-validation\n",
    "pred_y_list_all = []\n",
    "auc_score_list_all = []\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
    "print('Timestamp: {}'.format(timestamp))\n",
    "\n",
    "for i_fold in range(dataset.folds):\n",
    "    print('{}-th fold...'.format(i_fold))\n",
    "\n",
    "    # Load or train the model.\n",
    "    if ARGS.pretrained_model_file is not None:\n",
    "        model = load_grud_model(os.path.join(ARGS.working_path, \n",
    "                                             ARGS.pretrained_model_file.format(i_fold=i_fold)))\n",
    "    else:\n",
    "        model = create_grud_model(input_dim=dataset.input_dim,\n",
    "                                  output_dim=dataset.output_dim,\n",
    "                                  output_activation=dataset.output_activation,\n",
    "                                  recurrent_dim=ARGS.recurrent_dim,\n",
    "                                  hidden_dim=ARGS.hidden_dim,\n",
    "                                  predefined_model=ARGS.model,\n",
    "                                  use_bidirectional_rnn=ARGS.use_bidirectional_rnn\n",
    "                                 )\n",
    "        if i_fold == 0:\n",
    "            model.summary()\n",
    "        model.compile(optimizer='adam', loss=dataset.loss_function)\n",
    "        model.fit_generator(\n",
    "            generator=dataset.training_generator(i_fold, batch_size=ARGS.batch_size),\n",
    "            steps_per_epoch=dataset.training_steps(i_fold, batch_size=ARGS.batch_size),\n",
    "            epochs=ARGS.epochs,\n",
    "            verbose=1,\n",
    "            validation_data=dataset.validation_generator(i_fold, batch_size=ARGS.batch_size),\n",
    "            validation_steps=dataset.validation_steps(i_fold, batch_size=ARGS.batch_size),\n",
    "            callbacks=[\n",
    "                EarlyStopping(patience=ARGS.early_stopping_patience),\n",
    "                ModelCheckpointwithBestWeights(\n",
    "                    file_dir=os.path.join(ARGS.working_path, 'model', timestamp + '_' + str(i_fold))\n",
    "                ),\n",
    "                TensorBoard(\n",
    "                    log_dir=os.path.join(ARGS.working_path, 'tb_logs', timestamp + '_' + str(i_fold))\n",
    "                )\n",
    "            ]\n",
    "            )\n",
    "        model.save(os.path.join(ARGS.working_path, 'model', \n",
    "                                timestamp + '_' + str(i_fold), 'model.h5'))\n",
    "\n",
    "    # Evaluate the model\n",
    "    true_y_list = [\n",
    "        dataset.training_y(i_fold), dataset.validation_y(i_fold), dataset.testing_y(i_fold)\n",
    "    ]\n",
    "    pred_y_list = [\n",
    "        model.predict_generator(dataset.training_generator_x(i_fold, batch_size=ARGS.batch_size),\n",
    "                                steps=dataset.training_steps(i_fold, batch_size=ARGS.batch_size)),\n",
    "        model.predict_generator(dataset.validation_generator_x(i_fold, batch_size=ARGS.batch_size),\n",
    "                                steps=dataset.validation_steps(i_fold, batch_size=ARGS.batch_size)),\n",
    "        model.predict_generator(dataset.testing_generator_x(i_fold, batch_size=ARGS.batch_size),\n",
    "                                steps=dataset.testing_steps(i_fold, batch_size=ARGS.batch_size)),\n",
    "    ]\n",
    "    auc_score_list = [roc_auc_score(ty, py) for ty, py in zip(true_y_list, pred_y_list)] # [3, n_task]\n",
    "    print('AUC score of this fold: {}'.format(auc_score_list))\n",
    "    pred_y_list_all.append(pred_y_list)\n",
    "    auc_score_list_all.append(auc_score_list)\n",
    "\n",
    "print('Finished!', '='*20)\n",
    "auc_score_list_all = np.stack(auc_score_list_all, axis=0)\n",
    "print('Mean AUC score: {}; Std AUC score: {}'.format(\n",
    "    np.mean(auc_score_list_all, axis=0),\n",
    "    np.std(auc_score_list_all, axis=0)))\n",
    "\n",
    "result_path = os.path.join(ARGS.working_path, 'results', timestamp)\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "np.savez_compressed(os.path.join(result_path, 'predictions.npz'),\n",
    "                    pred_y_list_all=pred_y_list_all)\n",
    "np.savez_compressed(os.path.join(result_path, 'auroc_score.npz'),\n",
    "                    auc_score_list_all=auc_score_list_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2])\n",
    "b = np.array([[1,1,1],[1,1,1]])\n",
    "a.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
